{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# library required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "import nltk\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import LancasterStemmer, WordNetLemmatizer, PorterStemmer\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from textblob import TextBlob\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/niloofar/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import re\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "\n",
    "# Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "\n",
    "\n",
    "import nltk\n",
    "from nltk.stem.porter import *\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['from', 'subject', 're', 'edu', 'use'])\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "\n",
    "# spacy for lemmatization\n",
    "import spacy\n",
    "\n",
    "# Plotting tools\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim  # don't skip this\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Enable logging for gensim - optional\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explatory Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"/Users/niloofar/Downloads/Hotel_Reviews.csv\")\n",
    "\n",
    "# total number of hotels:\n",
    "\n",
    "len(set(df.Hotel_Name))\n",
    "df.Hotel_Name.value_counts()\n",
    "\n",
    "#change the format of time to datetime\n",
    "\n",
    "df['Review_Date']=pd.to_datetime(df['Review_Date'], format='%m/%d/%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selecting one sample hotel with highest number of review\n",
    "df1=df[df.Hotel_Name==\"Britannia International Hotel Canary Wharf\"]\n",
    "\n",
    "df1.index = range(df1.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Reviewer_Score'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data pre-processing for textual variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_text = pd.DataFrame(df1['Positive_Review'])\n",
    "data_text['Neg'] = df1['Negative_Review']\n",
    "data_text['index'] = data_text.index\n",
    "data_text.columns=['pos','neg','index']\n",
    "data_text['pos']=[\"  \" if x == 'No Positive' else x for x in data_text['pos']]\n",
    "data_text['neg']=[\"  \" if x == 'No Negative' else x for x in data_text['neg']]\n",
    "# data_text['review']=data_text['pos']+data_text['neg']\n",
    "# df=data_text['review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docp=list(sent_to_words(data_text['pos']))\n",
    "docn=list(sent_to_words(data_text['neg']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Time_Table=df1[['Review_Date','Reviewer_Score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Time_Table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_docn=list(data_text['neg'])\n",
    "pre_docp=list(data_text['pos'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop_list = [\"Nothing\",\"ok\",\"good\",\"great\",\"excellent\",\"very\",\"london\",\"nice\",\"lovely\",\"okay\",\"like\",\"wharf\",\"canary\",\"room\",\"amaze\",   \n",
    "#              'Indian','Italian','hotel','room','nothing','great','excellent','good','ideal','one','people','pleasant','wa']\n",
    "stop_words=['hotel','room','nothing','would','could','want','go','recommend','everything','be','was','good','ok','great','poor','miami','YVE']            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "import spacy\n",
    "from spacy.lemmatizer import Lemmatizer\n",
    "from spacy.lang.en import English, STOP_WORDS\n",
    "# from en_core_web_lg import *\n",
    "# import en_core_web_lg\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from pprint import pprint\n",
    "import pickle\n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(input_data, no_list,time_table,start, limit, step,file_name,verbose):\n",
    "    \n",
    "    #'''data pre processing using spacy '''\n",
    "    nlp = English()\n",
    "    lp= spacy.load(\"en\")\n",
    "    nlp.Defaults.stop_words.update(stop_words)\n",
    "\n",
    "    for word in STOP_WORDS:\n",
    "        lexeme = nlp.vocab[word]\n",
    "        lexeme.is_stop = True\n",
    "\n",
    "    flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "\n",
    "    def spacy_root(text):\n",
    "        nlp = spacy.load(\"en_core_web_sm\")\n",
    "        doc=[]\n",
    "        l=[]\n",
    "        for word in text:\n",
    "            ss=nlp(word)\n",
    "            for chunk in ss.noun_chunks:\n",
    "                l.append(chunk.root.text)\n",
    "        doc.append(l)\n",
    "        return(doc)\n",
    "\n",
    "\n",
    "    def lemmatizer(doc):\n",
    "        # This takes in a doc of tokens from the NER and lemmatizes them. \n",
    "        # Pronouns (like \"I\" and \"you\" get lemmatized to '-PRON-', so I'm removing those.\n",
    "        doc = [token.lemma_ for token in doc if token.lemma_ != '-PRON-']\n",
    "        doc = u' '.join(doc)\n",
    "        return nlp.make_doc(doc)\n",
    "\n",
    "    def remove_stopwords(doc):\n",
    "        spacy_nlp = spacy.load('en_core_web_sm')\n",
    "        spacy_stopwords = spacy.lang.en.stop_words.STOP_WORDS\n",
    "\n",
    "        for i in no_list:  \n",
    "            STOP_WORDS.add(i)\n",
    "\n",
    "        for word in STOP_WORDS:\n",
    "            lexeme = nlp.vocab[word]\n",
    "            lexeme.is_stop = True\n",
    "\n",
    "        tokens = [token.text for token in doc if not token.is_stop and token.is_punct != True and  len(token) >=3]\n",
    "        tokens=[i.lower() for i in tokens]\n",
    "        return tokens\n",
    "    nlp.add_pipe(lemmatizer,name='lemmatizer')\n",
    "    nlp.add_pipe(remove_stopwords, name=\"stopwords\", last=True)\n",
    "    nlp.add_pipe(spacy_root,name='root')\n",
    "\n",
    "    def compute_coherence_values(dictionary, corpus, texts, limit, start, step):\n",
    "\n",
    "        coherence_values = []\n",
    "        model_list = []\n",
    "        for num_topics in range(start, limit, step):\n",
    "#         model = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=num_topics, id2word=id2word)\n",
    "            model =gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                               id2word=dictionary,\n",
    "                                               num_topics=num_topics,\n",
    "                                               random_state=100,\n",
    "                                               update_every=1,\n",
    "                                               chunksize=100,\n",
    "                                               passes=10,\n",
    "                                               alpha='auto',\n",
    "                                               per_word_topics=True)\n",
    "            model_list.append(model)\n",
    "            coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "            coherence_values.append(coherencemodel.get_coherence())\n",
    "\n",
    "        return model_list, coherence_values\n",
    "    \n",
    "    \n",
    "     #build a topic model\n",
    "    \n",
    "    def format_topics_sentences(ldamodel, corpus, texts):\n",
    "    \n",
    "        sent_topics_df = pd.DataFrame()\n",
    "\n",
    "        # Get main topic in each document\n",
    "        for i, row_list in enumerate(ldamodel[corpus]):\n",
    "            row = row_list[0] if ldamodel.per_word_topics else row_list            \n",
    "            # print(row)\n",
    "            row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "            \n",
    "            # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
    "            for j, (topic_num, prop_topic) in enumerate(row):\n",
    "                if j == 0:  # => dominant topic\n",
    "                    wp = ldamodel.show_topic(topic_num)\n",
    "                    topic_keywords = \", \".join([word for word, prop in wp])\n",
    "                    sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
    "                else:\n",
    "                    break\n",
    "        sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
    "\n",
    "        # Add original text to the end of the output\n",
    "        contents = pd.Series(texts)\n",
    "        sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n",
    "        return(sent_topics_df)\n",
    "\n",
    "    if verbose==True:\n",
    "            \n",
    "    \n",
    "        doc_list = []\n",
    "        for doc in tqdm(input_data):\n",
    "            pr = nlp(doc)\n",
    "            doc_list.append(pr)\n",
    "            \n",
    "        dd=[flatten(i) for i in doc_list]\n",
    "        \n",
    "        with open(file_name, 'wb') as f:\n",
    "            pickle.dump(dd, f)\n",
    "        \n",
    "        \n",
    "    else:    \n",
    "        \n",
    "        with open(file_name, 'rb') as f:\n",
    "            dd = pickle.load(f)\n",
    "\n",
    "       \n",
    "    \n",
    "        \n",
    "    words = corpora.Dictionary(dd)\n",
    "    corpus = [words.doc2bow(doc) for doc in dd]\n",
    "    \n",
    "\n",
    "    model_list, coherence_values = compute_coherence_values(dictionary=words, corpus=corpus, texts=dd, start=start, limit=limit, step=step)\n",
    "    opt=coherence_values.index(max(coherence_values))\n",
    "    optimal_model=model_list[opt]\n",
    "\n",
    "    df_topic_sents_keywords = format_topics_sentences(ldamodel=optimal_model, corpus=corpus, texts=input_data)\n",
    "\n",
    "    # Format\n",
    "    df_dominant_topic = df_topic_sents_keywords.reset_index()\n",
    "    df_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']\n",
    "    df_dominant_topic=df_dominant_topic.merge(time_table, left_index=True, right_index=True)\n",
    "\n",
    "    return(df_dominant_topic)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "\n",
    "        with open ( path, 'rb' ) as f:\n",
    "            trip_ad = pickle.load ( f )\n",
    "            Time_Table = trip_ad[ [ 'Date' , 'rating' ] ]\n",
    "            # file_name = '/Users/niloofar/Documents/insight/data/cleaned/hotel2/doc_pos'\n",
    "            input_data = list ( trip_ad[ 'Review' ] )\n",
    "        return  input_data, Time_Table\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data, Time_Table=load_data(\"/Users/niloofar/Documents/insight/HotelWatch/data/trip_ad\")\n",
    "file_name=\"/Users/niloofar/Documents/insight/data/cleaned/hotel2/doc_pos\"\n",
    "\n",
    "Topic=process(input_data=input_data, no_list=stop_words,time_table=Time_Table,start=3, limit=15, step=1,file_name=file_name,verbose=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'location, restaurant, view, staff, downtown, miami, street, shop, breakfast, price',\n",
       " 'miami, service, place, desk, staff, experience, city, trip, love, time',\n",
       " 'night, cruise, bathroom, bed, day, elevator, time, book, floor, port',\n",
       " 'park, car, arena, block, towel, space, airlines, taxi, game, concert',\n",
       " 'water, coffee, deal, charge, pool, plan, year, fee, order, request'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(Topic.Keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"/Users/niloofar/Documents/insight/data/cleaned/hotel1/positive\", 'wb') as f:\n",
    "#             pickle.dump(positive_topic, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_topic=process(input_data=pre_docn, no_list=stop_words,time_table=Time_Table,start=3, limit=20, step=1,file_name=\"doc_neg\",verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"/Users/niloofar/Documents/insight/data/cleaned/hotel1/negative\", 'wb') as f:\n",
    "#             pickle.dump(negative_topic, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_pos=pd.DataFrame({\"Dominant_Topic\": [0,1,2,3,4,5,6,7,8],\n",
    "                    \"Topic_Name\":[\"Decoration\",\"facility\",\"location\",\n",
    "                                  \"price\",\"amenities\",\"parking\",\"general\",\"staff_receptionist\",\"Room_size\"]})\n",
    "                 \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_neg=pd.DataFrame({\"Dominant_Topic\": [0,1,2,3,4,5,6,7],\n",
    "                    \"Topic_Name\":[\"general\",\"service_food\",\"air_conditioning\",\n",
    "                                  \"staff_receptionist\",\"Decoration\",\"bed/bath/shower\",\"wifi\",\"parking\"]})\n",
    "                 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def table_modify (table,topic_table):\n",
    "    table=table.merge(topic_table, on=['Dominant_Topic'])\n",
    "#     table.loc[table.Topic_Perc_Contrib<0.3 ,'Topic_Name']='None'\n",
    "    return(table[['Document_No','Review_Date','Reviewer_Score','Topic_Name']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/Users/niloofar/Documents/insight/data/cleaned/hotel1/negative\",'rb') as f:\n",
    "        negative=pickle.load(f,encoding='latin1')\n",
    "        \n",
    "with open(\"/Users/niloofar/Documents/insight/data/cleaned/hotel1/positive\",'rb') as f:\n",
    "        positive=pickle.load(f,encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_topic=process(input_data=pre_docn, no_list=stop_words,time_table=Time_Table,start=3, limit=20, step=1,file_name=\"doc_neg\",verbose=False)\n",
    "positive_topic=process(input_data=pre_docp, no_list=stop_words,time_table=Time_Table,start=3, limit=20, step=1,file_name=\"doc_pos\",verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_topic_final=table_modify(positive_topic,topic_pos)\n",
    "neg_topic_final=table_modify(negative_topic,topic_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_topic_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def table_process(table_topic,input_data):\n",
    "    \n",
    "    \n",
    "    def sentiment_analyzer_scores(sentence):\n",
    "        analyser = SentimentIntensityAnalyzer()\n",
    "        score = analyser.polarity_scores(sentence)\n",
    "        return(\"{}\".format(str(score)))\n",
    "   \n",
    "    sentiment_eval=[sentiment_analyzer_scores(i) for i in input_data]\n",
    "    sent_score=[ast.literal_eval(i) for i in  sentiment_eval]\n",
    "    sent_table=pd.DataFrame(sent_score)\n",
    "    sent_table['Document_No']=sent_table.index\n",
    "    sent_table=sent_table[['compound','Document_No']]\n",
    "    table_sentiment=table_topic.merge(sent_table, on=['Document_No'])\n",
    "    table_sentiment.loc[table_sentiment.Topic_Name==\"None\" ,'compound']=0\n",
    "    return(table_sentiment)\n",
    "    \n",
    "#     return(table2.pivot(index='Document_No',columns='Topic_Name',values='neg'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_sentiment=table_process(pos_topic_final,pre_docp)\n",
    "neg_sentiment=table_process(neg_topic_final,pre_docn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tp=pos_sentiment[['Document_No','Topic_Name','compound']]\n",
    "Tn=neg_sentiment[['Document_No','Topic_Name','compound']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tp1=Tp.pivot(index='Document_No',columns='Topic_Name',values='compound')\n",
    "Tn1=Tn.pivot(index='Document_No',columns='Topic_Name',values='compound')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tp1=Tp1.drop(['None'],axis=1)\n",
    "Tn1=Tn1.drop(['None'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tp1.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_columns=list(set(Tp1.columns).intersection(Tn1.columns))\n",
    "common_columns.append('Document_No')\n",
    "# common_columns.remove('None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tp1=Tn1.merge(Tp1,on=common_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tp1=Tp1.drop(['None'],axis=1)\n",
    "Tp1=Tp1.fillna(0)\n",
    "Tp1=Tp1.merge(neg_topic_final[['Document_No','Review_Date','Reviewer_Score']],on=['Document_No'])\n",
    "# Tp1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_col=['general','Decoration','parking','staff_receptionist']\n",
    "Tp1['sum']=Tp1['air_conditioning']+Tp1['bed/bath/shower']+Tp1['service_food']+Tp1['wifi']+Tp1['Room_size']+Tp1['amenities']+Tp1['facility']+Tp1['location']+Tp1['price']\n",
    "Tp1=Tp1[Tp1['sum']!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/Users/niloofar/Documents/insight/data/cleaned/hotel1/Final_res\", 'wb') as f:\n",
    "            pickle.dump(Tp1, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/Users/niloofar/Documents/insight/data/cleaned/hotel1/Final_res\",'rb') as f:\n",
    "        df=pickle.load(f,encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xx=Tp1[['Decoration','Review_Date']]\n",
    "min(Tp1.Review_Date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tp1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns; sns.set()\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df=Tp1[(Tp1['Review_Date']>='2017-06-03') & (Tp1['Review_Date']<='2017-07-03')]\n",
    "\n",
    "colnames=['Document_No','sum','Review_Date']\n",
    "df=df.drop(colnames,axis=True)\n",
    "x_column=[i  for i in df.columns if i!=\"Reviewer_Score\"]\n",
    "\n",
    "x_column\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# from sklearn.datasets import make_classification\n",
    "# from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "# # # Build a classification task using 3 informative features\n",
    "\n",
    "# # # Build a forest and compute the feature importances\n",
    "\n",
    "# X, y = make_classification(n_samples=df.shape[0],\n",
    "#                            n_features=10,\n",
    "#                            n_informative=3,\n",
    "#                            n_redundant=0,\n",
    "#                            n_repeated=0,\n",
    "#                            n_classes=2,\n",
    "#                            random_state=0,\n",
    "#                            shuffle=False)\n",
    "\n",
    "# forest = ExtraTreesClassifier(n_estimators=250,\n",
    "#                               random_state=0)\n",
    "\n",
    "# forest.fit(X, y)\n",
    "# importances = forest.feature_importances_\n",
    "# std = np.std([tree.feature_importances_ for tree in forest.estimators_],\n",
    "#              axis=0)\n",
    "# indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# # Print the feature ranking\n",
    "# print(\"Feature ranking:\")\n",
    "\n",
    "# for f in range(X.shape[1]):\n",
    "#     print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n",
    "\n",
    "# # Plot the feature importances of the forest\n",
    "# plt.figure()\n",
    "# plt.title(\"Feature importances\")\n",
    "# plt.bar(range(X.shape[1]), importances[indices],\n",
    "#        color=\"r\", yerr=std[indices], align=\"center\")\n",
    "# plt.xticks(range(X.shape[1]), indices)\n",
    "# plt.xlim([-1, X.shape[1]])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = df.Reviewer_Score\n",
    "X = pd.DataFrame(df, columns = x_column)\n",
    "np.random.seed(seed = 42)\n",
    "# X['random'] = np.random.random(size = len(X))\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size = 0.8, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score,mean_squared_error\n",
    "from rfpimp import permutation_importances\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators = 100,\n",
    "                           n_jobs = -1,\n",
    "                           oob_score = True,\n",
    "                           bootstrap = True,\n",
    "                           random_state = 42)\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "def r2(rf, X_train, y_train):\n",
    "    return r2_score(y_train, rf.predict(X_train))\n",
    "\n",
    "model=permutation_importances(rf, X_train, y_train, r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reg=RidgeCV(alphas=np.arange(0.05,3.01,0.05),scoring=\"neg_mena_square_error\",cv=None).fit(X_train,y_train)\n",
    "# ridgeReg=Ridge(alpha=reg.alpha)\n",
    "# scores=cross_val_score(ridgeReg,X_train,y_train,cv=X_train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import RidgeCV,Ridge\n",
    "# ridgeReg.fit(X_train,y_train)\n",
    "# index=np.argsort(-ridgeReg.coef_)\n",
    "# ordered=[features[i] for i in index]\n",
    "# dataBar=[go.Bar(x=ordered,y=ridgeReg.coef_[index])]\n",
    "# plotly.offline.iplot(dataBar,filename=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lime\n",
    "import lime.lime_tabular\n",
    "\n",
    "explainer = lime.lime_tabular.LimeTabularExplainer(X_train.values,\n",
    "                                                   mode = 'regression',\n",
    "                                                   feature_names = X_train.columns,\n",
    "                                                   categorical_features = [8], \n",
    "                                                   categorical_names = ['CHAS'], \n",
    "                                                   discretize_continuous = True)\n",
    "                                                   \n",
    "np.random.seed(42)\n",
    "exp = explainer.explain_instance(X_valid.values[120], rf.predict, num_features = len(x_column))\n",
    "exp.show_in_notebook(show_all=False) #only the features used in the explanation are displayed\n",
    "\n",
    "exp = explainer.explain_instance(X_valid.values[12], rf.predict, num_features = len(x_column))\n",
    "exp.show_in_notebook(show_all=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import clone \n",
    "\n",
    "def drop_col_feat_imp(model, X_train, y_train, random_state = 42):\n",
    "    \n",
    "    # clone the model to have the exact same specification as the one initially trained\n",
    "    model_clone = clone(model)\n",
    "    # set random_state for comparability\n",
    "    model_clone.random_state = random_state\n",
    "    # training and scoring the benchmark model\n",
    "    model_clone.fit(X_train, y_train)\n",
    "    benchmark_score = model_clone.score(X_train, y_train)\n",
    "    # list for storing feature importances\n",
    "    importances = []\n",
    "    \n",
    "    # iterating over all columns and storing feature importance (difference between benchmark and new model)\n",
    "    for col in X_train.columns:\n",
    "        model_clone = clone(model)\n",
    "        model_clone.random_state = random_state\n",
    "        model_clone.fit(X_train.drop(col, axis = 1), y_train)\n",
    "        drop_col_score = model_clone.score(X_train.drop(col, axis = 1), y_train)\n",
    "        importances.append(benchmark_score - drop_col_score)\n",
    "    \n",
    "    importances_df = imp_df(X_train.columns, importances)\n",
    "    return importances_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop_col_feat_imp(model, X_train, y_train, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss=df.groupby('Review_Date').agg({'bed/bath/shower':['mean']})\n",
    "\n",
    "ss=pd.DataFrame(ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import sklearn\n",
    "import sklearn.datasets\n",
    "import sklearn.ensemble\n",
    "import numpy as np\n",
    "import lime\n",
    "import lime.lime_tabular\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predic_fn_rf=lambda x: model.rf.predict_proba(x).astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_topic.loc[25,'Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_topic[['Dominant_Topic','Keywords']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_topic_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa=[sentiment_analyzer_scores(i) for i in pre_docn]\n",
    "aa\n",
    "sent_score=[ast.literal_eval(i) for i in aa]\n",
    "SC=pd.DataFrame(sent_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table1=neg_topic_final[['Document_No','Topic_Name']]\n",
    "table2=table1.merge(SC, on=['Document_No'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_topic.loc[4784]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Slides preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# positive_topic=process(input_data=pre_docp, no_list=stop_words,time_table=Time_Table,start=2, limit=10, step=1,file_name=\"doc_pos\",verbose=False)\n",
    "\n",
    "with open('doc_pos', 'rb') as f:\n",
    "            dd = pickle.load(f)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = corpora.Dictionary(dd)\n",
    "corpus = [words.doc2bow(doc) for doc in dd]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_coherence_values(dictionary, corpus, texts, limit, start, step):\n",
    "\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for num_topics in range(start, limit, step):\n",
    "#         model = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=num_topics, id2word=id2word)\n",
    "        model =gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=dictionary,\n",
    "                                           num_topics=num_topics,\n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=True)\n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "\n",
    "    return model_list, coherence_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list, coherence_values = compute_coherence_values(dictionary=words, corpus=corpus, texts=dd, start=3, limit=15, step=1)\n",
    "opt=coherence_values.index(max(coherence_values))\n",
    "optimal_model=model_list[opt]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "limit=15; start=3; step=1;\n",
    "x = range(start, limit, step)\n",
    "plt.plot(x, coherence_values)\n",
    "plt.xlabel(\"Num Topics\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.legend((\"coherence_values\"), loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the model and print the topics\n",
    "optimal_model = model_list[7]\n",
    "model_topics = optimal_model.show_topics(formatted=False)\n",
    "pprint(optimal_model.print_topics(num_words=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis\n",
    "import pyLDAvis.gensim  # don't skip this\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim.prepare(optimal_model, corpus, words)\n",
    "vis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/niloofar/Documents/insight/data/cleaned/hotel2/trip_ad', 'rb') as f:\n",
    "            trip_ad= pickle.load(f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_ad.head()\n",
    "Time_Table=trip_ad[['Date','rating']]\n",
    "file_name='/Users/niloofar/Documents/insight/data/cleaned/hotel2/doc_pos'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Topic=process(input_data=list(trip_ad['Review']), no_list=stop_words,time_table=Time_Table,start=3, limit=20, step=1,file_name=file_name,verbose=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Topic[\"Keywords\"][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Topic[\"Text\"][2649]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(Topic['Dominant_Topic']).value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_table=pd.DataFrame({\"Dominant_Topic\": [8,0,2,4,6],\n",
    "                    \"Topic_Name\":[\"amenities\",\"location\",\"staff\",\n",
    "                                  \"extra_charge\",\"parking\"]})\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Topic[\"Date\"]= pd.to_datetime(Topic[\"Date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table=Topic.merge(topic_table, on=['Dominant_Topic'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_topic=table_process(table,list(trip_ad['Review']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_topic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_topic[\"Text\"][2653]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_topic[\"compound\"][2653]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from datetime import date, timedelta\n",
    "\n",
    "sdate = date(2013, 1, 1)   # start date\n",
    "edate = date(2020, 1, 1)   # end date\n",
    "delta = edate - sdate\n",
    "year=(delta/365).days\n",
    "\n",
    "Date=[]\n",
    "for i in range(0,year):\n",
    "    if i==3:\n",
    "        pt=sdate + timedelta(days=366)\n",
    "    else:    \n",
    "        pt=sdate + timedelta(days=365)\n",
    "    Date.append([sdate,pt])\n",
    "    sdate=pt\n",
    "\n",
    "# Date=[i.strftime('%Y-%m-%d') for i in Date]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [date_obj.strftime('%Y%m%d') for date_obj in mondays]\n",
    "\n",
    "# flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "# P=flatten(Date)\n",
    "# P=[i.strftime('%Y-%m') for i in P]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import math as m\n",
    "# K=[]\n",
    "# for i in range(0, m.ceil(len(P)/2)):\n",
    "#     a= P[:2]\n",
    "#     K.append(a)\n",
    "#     P=P[2:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K=[Date[i][0].year for i in range(0,len(Date))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_topic_final=sentiment_topic.pivot(index='Document_No',columns='Topic_Name',values='compound').fillna(0)\n",
    "sentiment_topic_final=sentiment_topic_final.merge(sentiment_topic[['Document_No','Date','rating']],on=['Document_No'])\n",
    "sentiment_topic_final.columns=['Document_No','amenities','extra_charge','location','parking','staff','Review_Date','Reviewer_Score']\n",
    "col_list=list(topic_table.Topic_Name)\n",
    "sentiment_topic_final['sum']=sentiment_topic_final[col_list].sum(axis=1)\n",
    "# with open('sentiment_topic_final', 'wb') as f:\n",
    "#     pickle.dump('/Users/niloofar/Documents/insight/data/cleaned/hotel2/sentiment_topic_final', f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(sentiment_topic_final.Review_Date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss=sentiment_topic_final.loc[(sentiment_topic_final.Review_Date>=Date[0][0]) & (sentiment_topic_final.Review_Date<Date[0][1])]\n",
    "# ss.Review_Date = [i.strftime(\"%Y-%m-%d\") for i in ss.Review_Date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb=set(ss.Time)\n",
    "nn=sorted([i.strftime(\"%Y-%m-%d\") for i in bb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss=pd.DataFrame(ss)\n",
    "ss.Reviewer_Score=[int(i) for i in ss.Reviewer_Score]\n",
    "ss=ss.groupby(['Review_Date'])['Reviewer_Score'].mean()\n",
    "ss=pd.DataFrame(ss)\n",
    "ss=pd.DataFrame({'Time':ss.index,'Score':ss.Reviewer_Score})\n",
    "# ss=pf.DataFrame({'Date':ss.index})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
